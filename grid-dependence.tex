\subsubsection{Dependence on background grid}\label{sec:grid-dependence}

The serial Algorithms \ref{algo:par-interp} and \ref{algo:serial-spread} do not
explicitly depend on the size of the fluid grid. With perhaps the exception of the
sorting and reducing steps, Algorithm \ref{algo:par-spread} also does not depend on the
size of the grid. Algorithms \ref{algo:pa-spread} and \ref{algo:otf-spread}, on the other
hand, ultimately sum their buffer vectors, which have one entry per grid point. Algorithm
\ref{algo:otf-spread} also incorporates the allocation of these buffers. Using a few
different fluid grids, we investigate whether Algorithms \ref{algo:par-interp} and
\ref{algo:par-spread} are independent of the grid in practice, and how the grid
dependence affects the runtime of Algorithms \ref{algo:pa-spread} and
\ref{algo:otf-spread}.
%

\begin{table}[ht]
    \begin{center}
    \bgroup
    \renewcommand{\arraystretch}{1.7}
    \begin{tabular}{ccccccc}
                                                                                              \toprule
                             &                          & \multicolumn{4}{c}{Grid refinement}   \\ \cline{3-6}
        Device               & Algorithm                & 16      & 32      & 64      & 128     \\ \midrule
        $1\times\text{CPU}$  & \ref{algo:par-interp}    & 1.29633 & 1.31373 & 1.30763 & 1.35101 \\
                             & \ref{algo:serial-spread} & 1.33249 & 1.33621 & 1.33840 & 1.37281 \\ \midrule
        $16\times\text{CPU}$ & \ref{algo:par-interp}    & 0.09890 & 0.09928 & 0.09974 & 0.10624 \\
                             & \ref{algo:par-spread}    & 0.23282 & 0.26431 & 0.25783 & 0.26590 \\
                             & \ref{algo:pa-spread}     & 0.12803 & 0.14213 & 0.15215 & 0.20107 \\
                             & \ref{algo:otf-spread}    & 0.12965 & 0.14242 & 0.14766 & 0.21874 \\ \midrule
        $1\times\text{GPU}$  & \ref{algo:par-interp}    & 0.01253 & 0.01317 & 0.01722 & 0.01816 \\
                             & \ref{algo:par-spread}    & 0.03930 & 0.04020 & 0.04215 & 0.04755 \\
                             & \ref{algo:pa-spread}     & 0.01715 & 0.02049 & 0.02370 & 0.03656 \\
                             & \ref{algo:otf-spread}    & 0.01804 & 0.02198 & 0.02873 & 0.07288 \\ \bottomrule
    \end{tabular}
    \egroup
    \end{center}
    \caption{%
Average timing results for interpolating to and spreading from $2^{16}$ IB points from
1000 timesteps on different devices and grid configurations. Interpolation (Algorithm
\ref{algo:par-interp}) happens twice per timestep and spreading (Algorithms
\ref{algo:serial-spread}, \ref{algo:par-spread}--\ref{algo:otf-spread}) happens once per
timestep. Grid refinement is the number of grid points per $16\um$ in each dimension.
Times per call to the listed algorithm are reported in seconds.
    }
    \label{tab:grid-timing}
\end{table}

Table \ref{tab:grid-timing} lists timing results for $n=2^{16}$ IB points and 16, 32, 64,
and 128 grid points per $16\um$. The rows with device listed as $1\times\text{CPU}$
correspond to the serial algorithms and will serve as a reference point for the rest of
the section. If the serial algorithms depend on the fluid grid, they do so only mildly.
In fact, under close scrutiny, it seems that these deviations are due to hardware-level
differences in the integer multiplications and additions used in computing sort keys and
grid indices. We can therefore expect each of the algorithms to exhibit a mild variation
in runtime for different grid refinements.

%The segmented reduce in Algorithms \ref{algo:par-spread}, \ref{algo:pa-spread},
%and \ref{algo:otf-spread} each have an implicit dependence on the fluid grid.
%For a fixed number of IB points, increasing the grid refinement from 16 to 128
%reduces the density of the IB points from 16 points per grid cell to 1 point
%per every 32 grid cell, on average. If each point inhabits its own grid cell,
%the segmented reduce does not have any useful work to do, as the result is the
%same as the input. On the other hand, if every IB point is in the same grid
%cell, segmented reduce proceeds very similarly to a normal reduce operation,
%which can effectively leverage the memory heirarchy (cache and/or shared
%memory). This, in turn, makes the algorithm extremely fast. As a result, we
%would expect that in those tests where point density is high, the algorithm
%will perform better than those tests with low point density. Once the
%density reaches one point per grid cell, we do not expect segmented reduce
%to vary under refinement of the background grid.

\begin{figure}[ht]
\begin{tikzpicture}
\begin{groupplot}[
    group style={group name=dep, group size=2 by 1},
]
\nextgroupplot[
        xmin=12,
        xmax=160,
        xmode=log,
        log basis x=2,
        ymin=3,
        ymax=24,
        ymode=log,
        log basis y=2,
        log origin=infty,
        ytick={2, 4, 8, 16},
        width=0.5\textwidth,
        height=0.5\textwidth,
        axis lines=center,
        xlabel={grid refinement},
        ylabel={speedup},
        xlabel near ticks,
        ylabel near ticks
    ]
    
    \addplot+[only marks, mark=diamond*, color=tol/vibrant/magenta, mark options={fill=tol/vibrant/magenta}] coordinates {%
        (16 , {1.44570/0.09890})
        (32 , {1.45665/0.09928})
        (64 , {1.46783/0.09974})
        (128, {1.51988/0.10624})
    }; \label{plot:grid-dep-interp};
    \addplot+[only marks, mark=square*, color=tol/vibrant/teal, mark options={fill=tol/vibrant/teal}] coordinates {%
        (16 , {1.47196/0.23282})
        (32 , {1.48014/0.26431})
        (64 , {1.48519/0.25783})
        (128, {1.53801/0.26590})
    }; \label{plot:grid-dep-spread};
    \addplot+[only marks, mark=*, color=tol/vibrant/orange, mark options={fill=tol/vibrant/orange}] coordinates {%
        (16 , {1.47196/0.12803})
        (32 , {1.48014/0.14213})
        (64 , {1.48519/0.15215})
        (128, {1.53801/0.20107})
    }; \label{plot:grid-dep-pa};
    \addplot+[only marks, mark=triangle*, color=tol/vibrant/blue, mark options={fill=tol/vibrant/blue}] coordinates {%
        (16 , {1.47196/0.12965})
        (32 , {1.48014/0.14242})
        (64 , {1.48519/0.14766})
        (128, {1.53801/0.21874})
    }; \label{plot:grid-dep-otf};
    \node [fill=white] at (rel axis cs: 0.075, 0.95) {(a)};
\nextgroupplot[
    xmin=12,
    xmax=192,
    xmode=log,
    log basis x=2,
    ymin=12,
    ymax=160,
    ymode=log,
    log basis y=2,
    log origin=infty,
    ytick={16, 32, 64, 128},
    width=0.5\textwidth,
    height=0.5\textwidth,
    axis lines=center,
    xlabel={grid refinement},
    xlabel near ticks,
    ylabel near ticks
]
    \addplot+[only marks, mark=diamond*, color=tol/vibrant/magenta, mark options={fill=tol/vibrant/magenta}] coordinates {%
        (16 , {1.44570/0.01253})
        (32 , {1.45665/0.01317})
        (64 , {1.46783/0.01722})
        (128, {1.51988/0.01816})
    };
    \addplot+[only marks, mark=square*, color=tol/vibrant/teal, mark options={fill=tol/vibrant/teal}] coordinates {%
        (16 , {1.47196/0.03930})
        (32 , {1.48014/0.04020})
        (64 , {1.48519/0.04215})
        (128, {1.53801/0.04755})
    };
    \addplot+[only marks, mark=*, color=tol/vibrant/orange, mark options={fill=tol/vibrant/orange}] coordinates {%
        (16 , {1.47196/0.01715})
        (32 , {1.48014/0.02049})
        (64 , {1.48519/0.02370})
        (128, {1.53801/0.03656})
    };
    \addplot+[only marks, mark=triangle*, color=tol/vibrant/blue, mark options={fill=tol/vibrant/blue}] coordinates {%
        (16 , {1.47196/0.01804})
        (32 , {1.48014/0.02198})
        (64 , {1.48519/0.02873})
        (128, {1.53801/0.07288})
    };
    \node [fill=white] at (rel axis cs: 0.075, 0.95) {(b)};
\end{groupplot}
\path (dep c1r1.south west|-current bounding box.south)--
coordinate(legendpos) (dep c2r1.south east|-current bounding box.south);
\matrix[
    matrix of nodes,
    anchor=north,
    inner sep=0.2em,
    %draw
  ]at([yshift=-1ex]legendpos)
  {
    \ref{plot:grid-dep-interp}& Algorithm \ref{algo:par-interp}&[5pt]
    \ref{plot:grid-dep-spread}& Algorithm \ref{algo:par-spread}&[5pt]
    \ref{plot:grid-dep-pa}& Algorithm \ref{algo:pa-spread}&[5pt]
    \ref{plot:grid-dep-otf}& Algorithm \ref{algo:otf-spread}\\};
\end{tikzpicture}
\caption{%
Speedup of Algorithm \ref{algo:par-interp} (interpolation) and Algorithms
\ref{algo:par-spread}--\ref{algo:otf-spread} (spreading) compared to their serial
counterparts on $2^{16}$ randomly placed IB points for different grid refinements on (a)
16 CPUs and (b) the GPU. 
}
\label{fig:grid-dependence}
\end{figure}

The speedup for these schemes is illustrated in Figure \ref{fig:grid-dependence}.
Algorithm \ref{algo:par-interp} is independent of the fluid grid, as expected. Any grid
dependence introduced by the sort and reduce steps of Algorithm \ref{algo:par-spread} is
not obvious for the grids presented. On the other hand, the degradation of speedup for
the sweep-fused Algorithms \ref{algo:pa-spread} and \ref{algo:otf-spread} is apparent for
finer grids. For small problems with $128^3$ or fewer grid points, one gets better
performance from the sweep-fused variants, with the exception of Algorithm
\ref{algo:otf-spread} on the GPU. This can be attributed to the slower allocation of the
buffer for a finer grid. For problems where the grid has $256^3$ or more grid points, we
expect Algorithm \ref{algo:par-spread} to be the fastest choice for spreading. Because
our fluid solver fits in GPU memory only for fewer than $128^3$ grid points, for the
remainder of this work we consider only a grid with a grid refinement of 64 ($h =
0.25\um$). We can imagine using this algorithm on a less capable device with more limited
memory, so we restrict ourselves to Algorithm \ref{algo:otf-spread} for spreading,
computing $\bufsz=8$ values per sweep, to minimize the lifetime of the buffer used in
spreading while still enjoying the benefit of using the buffer.

% vim: cc=90 tw=89
