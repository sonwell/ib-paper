\subsubsection{Dependence on background grid}

The serial Algorithms \ref{algo:par-interp} and \ref{algo:serial-spread}
do not explicitly depend on the size of the fluid grid. Perhaps with the
exception of the sorting and reducing steps, Algorithm \ref{algo:par-spread}
also does not depend on the size of the grid. Algorithms \ref{algo:pa-spread}
and \ref{algo:otf-spread}, on the other hand, ultimately sum their buffer
vectors, which have one entry per grid point. Algorithm \ref{algo:otf-spread}
also incorporates the allocation of these buffers. Using a few different fluid
grids, we investigate whether Algorithms \ref{algo:par-interp} and
\ref{algo:par-spread} are independent of the grid in practice, and how the grid
dependence affects the runtime of Algorithms \ref{algo:pa-spread} and
\ref{algo:otf-spread}.
%

\begin{table}
    \begin{center}
    \bgroup
    \renewcommand{\arraystretch}{1.7}
    \begin{tabular}{ccccccc}
                                                                                              \toprule
                             &                          & \multicolumn{4}{c}{Grid refinement}   \\ \cline{3-6}
        Device               & Algorithm                & 16      & 32      & 64      & 128     \\ \midrule
        $1\times\text{CPU}$  & \ref{algo:par-interp}    & 1.29633 & 1.31373 & 1.30763 & 1.35101 \\
                             & \ref{algo:serial-spread} & 1.33249 & 1.33621 & 1.33840 & 1.37281 \\ \midrule
        $16\times\text{CPU}$ & \ref{algo:par-interp}    & 0.09890 & 0.09928 & 0.09974 & 0.10624 \\
                             & \ref{algo:par-spread}    & 0.23282 & 0.26431 & 0.25783 & 0.26590 \\
                             & \ref{algo:pa-spread}     & 0.12803 & 0.14213 & 0.15215 & 0.20107 \\
                             & \ref{algo:otf-spread}    & 0.12965 & 0.14242 & 0.14766 & 0.21874 \\ \midrule
        $1\times\text{GPU}$  & \ref{algo:par-interp}    & 0.01253 & 0.01317 & 0.01722 & 0.01816 \\
                             & \ref{algo:par-spread}    & 0.03930 & 0.04020 & 0.04215 & 0.04755 \\
                             & \ref{algo:pa-spread}     & 0.01715 & 0.02049 & 0.02370 & 0.03656 \\
                             & \ref{algo:otf-spread}    & 0.01804 & 0.02198 & 0.02873 & 0.07288 \\ \bottomrule
    \end{tabular}
    \egroup
    \end{center}
    \caption{%
        Timing results for interpolation and spreading on different devices and
        grid configurations. Grid refinement is the number of grid points per
        $16\um$ in each dimension. Times are reported in seconds.
    }
    \label{tab:grid-timing}
\end{table}

Table \ref{tab:grid-timing} lists timing results for this test case with
$n=2^{16}$ IB points and 16, 32, 64, and 128 grid points per $16\um$.
The rows with device listed as $1\times\text{CPU}$ correspond to the serial
algorithms and will serve as a reference point for the rest of the section. If
the serial algorithms depend on the fluid grid, they do so only mildly. In
fact, under close scrutiny, it seems that these deviations are due to
hardware-level differences in the integer multiplications and additions used in
computing sort and grid indices. We can therefore expect each of the algorithms
to exhibit a mild variation in runtime for different grid refinements.

%The segmented reduce in Algorithms \ref{algo:par-spread}, \ref{algo:pa-spread},
%and \ref{algo:otf-spread} each have an implicit dependence on the fluid grid.
%For a fixed number of IB points, increasing the grid refinement from 16 to 128
%reduces the density of the IB points from 16 points per grid cell to 1 point
%per every 32 grid cell, on average. If each point inhabits its own grid cell,
%the segmented reduce does not have any useful work to do, as the result is the
%same as the input. On the other hand, if every IB point is in the same grid
%cell, segmented reduce proceeds very similarly to a normal reduce operation,
%which can effectively leverage the memory heirarchy (cache and/or shared
%memory). This, in turn, makes the algorithm extremely fast. As a result, we
%would expect that in those tests where point density is high, the algorithm
%will perform better than those tests with low point density. Once the
%density reaches one point per grid cell, we do not expect segmented reduce
%to vary under refinement of the background grid.

\begin{figure}[h]
\begin{tikzpicture}
\begin{groupplot}[
    group style={group name=dep, group size=2 by 1},
]
\nextgroupplot[
        xmin=12,
        xmax=160,
        xmode=log,
        log basis x=2,
        ymin=3,
        ymax=24,
        ymode=log,
        log basis y=2,
        log origin=infty,
        ytick={2, 4, 8, 16},
        width=0.5\textwidth,
        height=0.5\textwidth,
        axis lines=center,
        xlabel={grid refinement},
        ylabel={speedup},
        xlabel near ticks,
        ylabel near ticks
    ]
    
    \addplot+[only marks, mark=diamond*, color=tol/vibrant/magenta, mark options={fill=tol/vibrant/magenta}] coordinates {%
        (16 , {1.44570/0.09890})
        (32 , {1.45665/0.09928})
        (64 , {1.46783/0.09974})
        (128, {1.51988/0.10624})
    }; \label{plot:grid-dep-interp};
    \addplot+[only marks, mark=square*, color=tol/vibrant/teal, mark options={fill=tol/vibrant/teal}] coordinates {%
        (16 , {1.47196/0.23282})
        (32 , {1.48014/0.26431})
        (64 , {1.48519/0.25783})
        (128, {1.53801/0.26590})
    }; \label{plot:grid-dep-spread};
    \addplot+[only marks, mark=*, color=tol/vibrant/orange, mark options={fill=tol/vibrant/orange}] coordinates {%
        (16 , {1.47196/0.12803})
        (32 , {1.48014/0.14213})
        (64 , {1.48519/0.15215})
        (128, {1.53801/0.20107})
    }; \label{plot:grid-dep-pa};
    \addplot+[only marks, mark=triangle*, color=tol/vibrant/blue, mark options={fill=tol/vibrant/blue}] coordinates {%
        (16 , {1.47196/0.12965})
        (32 , {1.48014/0.14242})
        (64 , {1.48519/0.14766})
        (128, {1.53801/0.21874})
    }; \label{plot:grid-dep-otf};
    \node [fill=white] at (rel axis cs: 0.075, 0.95) {(a)};
\nextgroupplot[
    xmin=12,
    xmax=192,
    xmode=log,
    log basis x=2,
    ymin=12,
    ymax=160,
    ymode=log,
    log basis y=2,
    log origin=infty,
    ytick={16, 32, 64, 128},
    width=0.5\textwidth,
    height=0.5\textwidth,
    axis lines=center,
    xlabel={grid refinement},
    xlabel near ticks,
    ylabel near ticks
]
    \addplot+[only marks, mark=diamond*, color=tol/vibrant/magenta, mark options={fill=tol/vibrant/magenta}] coordinates {%
        (16 , {1.44570/0.01253})
        (32 , {1.45665/0.01317})
        (64 , {1.46783/0.01722})
        (128, {1.51988/0.01816})
    };
    \addplot+[only marks, mark=square*, color=tol/vibrant/teal, mark options={fill=tol/vibrant/teal}] coordinates {%
        (16 , {1.47196/0.03930})
        (32 , {1.48014/0.04020})
        (64 , {1.48519/0.04215})
        (128, {1.53801/0.04755})
    };
    \addplot+[only marks, mark=*, color=tol/vibrant/orange, mark options={fill=tol/vibrant/orange}] coordinates {%
        (16 , {1.47196/0.01715})
        (32 , {1.48014/0.02049})
        (64 , {1.48519/0.02370})
        (128, {1.53801/0.03656})
    };
    \addplot+[only marks, mark=triangle*, color=tol/vibrant/blue, mark options={fill=tol/vibrant/blue}] coordinates {%
        (16 , {1.47196/0.01804})
        (32 , {1.48014/0.02198})
        (64 , {1.48519/0.02873})
        (128, {1.53801/0.07288})
    };
    \node [fill=white] at (rel axis cs: 0.075, 0.95) {(b)};
\end{groupplot}
\path (dep c1r1.south west|-current bounding box.south)--
coordinate(legendpos) (dep c2r1.south east|-current bounding box.south);
\matrix[
    matrix of nodes,
    anchor=north,
    inner sep=0.2em,
    %draw
  ]at([yshift=-1ex]legendpos)
  {
    \ref{plot:grid-dep-interp}& Algorithm \ref{algo:par-interp}&[5pt]
    \ref{plot:grid-dep-spread}& Algorithm \ref{algo:par-spread}&[5pt]
    \ref{plot:grid-dep-pa}& Algorithm \ref{algo:pa-spread}&[5pt]
    \ref{plot:grid-dep-otf}& Algorithm \ref{algo:otf-spread}\\};
\end{tikzpicture}
\caption{%
    Speedup from parallel interpolation (Algorithm \ref{algo:par-interp})
    and spread (Algorithms \ref{algo:par-spread}--\ref{algo:otf-spread})
    compared to their serial counterparts on $2^{16}$ randomly placed IB points
    for different grid refinements on (a) 16 CPUs and (b) the GPU. 
}
\label{fig:grid-dependence}
\end{figure}

The speedup for these parallelization schemes is illustrated in Figure
\ref{fig:grid-dependence}. Algorithm \ref{algo:par-interp} is independent of
the fluid grid, as expected. Any grid dependence introduced by the sort and
reduce steps of Algorithm \ref{algo:par-spread} is not obvious for the grids
presented. On the other hand, the degradation of speedup for the sweep-fused
Algorithms \ref{algo:pa-spread} and \ref{algo:otf-spread} is apparent for finer
grids. For small problems with $128^3$ or fewer grid points, one gets better
performance from the sweep-fused spread variants, with the exception of
Algorithm \ref{algo:otf-spread} on the GPU. This is attributed to the slower
allocation of the buffer for a finer grid. For problems where the grid has
$256^3$ or more grid points, we expect Algorithm \ref{algo:par-spread} to be
the fastest choice for spread. Because our fluid solver fits in GPU memory only
for fewer than $128^3$ grid points, for the remainder of this work we consider
only a grid with a grid refinement of 64 ($h = 0.25\um$). We can imagine using
this algorithm on a less capable device with more limited memory, so we
restrict ourselves to Algorithm \ref{algo:otf-spread} for spread, computing
$\texttt{sz}=8$ values per sweep, to minimize the lifetime of the buffer used
in spreading while still enjoying the benefit of using the buffer.
